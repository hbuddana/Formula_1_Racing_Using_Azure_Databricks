{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bfdfdd2-8c7c-49ad-9809-10e515ce61c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 1 - Read the CSV file using the spark dataframe reader API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe3884ec-2e46-40ce-b557-e472cb657b82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9de465ea-e4cf-4bcd-af1b-fa8286cbf7e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), False),\n",
    "                                  StructField(\"year\", IntegerType(), True),\n",
    "                                  StructField(\"round\", IntegerType(), True),\n",
    "                                  StructField(\"circuitId\", IntegerType(), True),\n",
    "                                  StructField(\"name\", StringType(), True),\n",
    "                                  StructField(\"date\", DateType(), True),\n",
    "                                  StructField(\"time\", StringType(), True),\n",
    "                                  StructField(\"url\", StringType(), True) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bff73fd-b034-4470-b6d3-c363de0a67c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_account_name = \"formula1dl099\"\n",
    "container_name = \"raw\"\n",
    "csv_file_name = \"races.csv\"\n",
    "\n",
    "csv_file_path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{csv_file_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7538d632-f411-40f7-8a13-c22ae56bd795",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_df = spark.read.csv(csv_file_path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4498f56-c66b-4f2e-9d76-84cae8729a97",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 2 - Add ingestion date and race_timestamp to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52464782-37c1-44f1-9b74-8db0f42c6d64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, to_timestamp, concat, col, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b65cdbd8-295a-4bf1-b984-cee0b342edbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_with_timestamp_df = races_df.withColumn(\"ingestion_date\", current_timestamp()) \\\n",
    "                                  .withColumn(\"race_timestamp\", to_timestamp(concat(col('date'), lit(' '), col('time')), 'yyyy-MM-dd HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00c3655d-ed11-4506-b21a-8c7797311473",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 3 - Select only the columns required & rename as required\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f4ec60-d58c-4656-b2b2-34a2af41a731",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_selected_df = races_with_timestamp_df.select(col('raceId').alias('race_id'), col('year').alias('race_year'), \n",
    "                                                   col('round'), col('circuitId').alias('circuit_id'),col('name'), col('ingestion_date'), col('race_timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1bf1ffc-d9f7-458d-a45d-3c2bc1c11161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+----------+--------------------+--------------------+-------------------+\n|race_id|race_year|round|circuit_id|                name|      ingestion_date|     race_timestamp|\n+-------+---------+-----+----------+--------------------+--------------------+-------------------+\n|      1|     2009|    1|         1|Australian Grand ...|2023-12-24 18:35:...|2009-03-29 06:00:00|\n|      2|     2009|    2|         2|Malaysian Grand Prix|2023-12-24 18:35:...|2009-04-05 09:00:00|\n|      3|     2009|    3|        17|  Chinese Grand Prix|2023-12-24 18:35:...|2009-04-19 07:00:00|\n|      4|     2009|    4|         3|  Bahrain Grand Prix|2023-12-24 18:35:...|2009-04-26 12:00:00|\n|      5|     2009|    5|         4|  Spanish Grand Prix|2023-12-24 18:35:...|2009-05-10 12:00:00|\n|      6|     2009|    6|         6|   Monaco Grand Prix|2023-12-24 18:35:...|2009-05-24 12:00:00|\n|      7|     2009|    7|         5|  Turkish Grand Prix|2023-12-24 18:35:...|2009-06-07 12:00:00|\n|      8|     2009|    8|         9|  British Grand Prix|2023-12-24 18:35:...|2009-06-21 12:00:00|\n|      9|     2009|    9|        20|   German Grand Prix|2023-12-24 18:35:...|2009-07-12 12:00:00|\n|     10|     2009|   10|        11|Hungarian Grand Prix|2023-12-24 18:35:...|2009-07-26 12:00:00|\n|     11|     2009|   11|        12| European Grand Prix|2023-12-24 18:35:...|2009-08-23 12:00:00|\n|     12|     2009|   12|        13|  Belgian Grand Prix|2023-12-24 18:35:...|2009-08-30 12:00:00|\n|     13|     2009|   13|        14|  Italian Grand Prix|2023-12-24 18:35:...|2009-09-13 12:00:00|\n|     14|     2009|   14|        15|Singapore Grand Prix|2023-12-24 18:35:...|2009-09-27 12:00:00|\n|     15|     2009|   15|        22| Japanese Grand Prix|2023-12-24 18:35:...|2009-10-04 05:00:00|\n|     16|     2009|   16|        18|Brazilian Grand Prix|2023-12-24 18:35:...|2009-10-18 16:00:00|\n|     17|     2009|   17|        24|Abu Dhabi Grand Prix|2023-12-24 18:35:...|2009-11-01 11:00:00|\n|     18|     2008|    1|         1|Australian Grand ...|2023-12-24 18:35:...|2008-03-16 04:30:00|\n|     19|     2008|    2|         2|Malaysian Grand Prix|2023-12-24 18:35:...|2008-03-23 07:00:00|\n|     20|     2008|    3|         3|  Bahrain Grand Prix|2023-12-24 18:35:...|2008-04-06 11:30:00|\n+-------+---------+-----+----------+--------------------+--------------------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "races_selected_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b496515a-8752-4573-aa31-61c2bbcedc7a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 4 - Write the output to processed container in parquet format\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72682431-8432-487d-9dfd-27991c235b48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_selected_df.write.mode('overwrite').partitionBy('race_year').parquet('abfss://processed@formula1dl099.dfs.core.windows.net/races')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "540c7d5c-22ea-4f12-890f-9c3274777f37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.ingest_races_file",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
